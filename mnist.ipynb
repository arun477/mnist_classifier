{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import fastcore.all as fc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import default_collate, DataLoader\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nm = 'mnist'\n",
    "x,y = 'image', 'label'\n",
    "ds = load_dataset(dataset_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ds(b):\n",
    "    b[x] = [TF.to_tensor(ele) for ele in b[x]]\n",
    "    return b\n",
    "\n",
    "dst = ds.with_transform(transform_ds)\n",
    "plt.imshow(dst['train'][0]['image'].permute(1,2,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "class DataLoaders:\n",
    "    def __init__(self, train_ds, valid_ds, bs, collate_fn, **kwargs):\n",
    "        self.train = DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, **kwargs)\n",
    "        self.valid = DataLoader(train_ds, batch_size=bs*2, shuffle=False, collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "def collate_fn(b):\n",
    "    collate = default_collate(b)\n",
    "    return (collate[x], collate[y])\n",
    "\n",
    "dls = DataLoaders(dst['train'], dst['test'], bs=bs, collate_fn=collate_fn)\n",
    "xb,yb = next(iter(dls.train))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.reshape(self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_classifier():\n",
    "    ks,stride = 3,2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 4, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(4, 8, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(8, 16, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 32, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 10, kernel_size=ks, stride=stride, padding=ks//2),\n",
    "        nn.Flatten(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classifier():\n",
    "    return nn.Sequential(\n",
    "        Reshape((-1, 784)),\n",
    "        nn.Linear(784, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_classifier()\n",
    "lr = 0.1\n",
    "max_lr = 0.1\n",
    "epochs = 5\n",
    "opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "sched = optim.lr_scheduler.OneCycleLR(opt, max_lr, total_steps=len(dls.train), epochs=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for train in (True, False):\n",
    "        accuracy = 0\n",
    "        dl = dls.train if train else dls.valid\n",
    "        for xb,yb in dl:\n",
    "            preds = model(xb)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                accuracy += (preds.argmax(1).detach().cpu() == yb).float().mean()\n",
    "        if train:\n",
    "            sched.step()\n",
    "        accuracy /= len(dl)\n",
    "        print(f\"{'train' if train else 'eval'}, epoch:{epoch+1}, loss: {loss.item():.4f}, accuracy: {accuracy:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./linear_classifier.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    #whiteboard {\n",
    "        border: 3px solid black;\n",
    "        border-radius: 6px;  \n",
    "        background-color: #FFFFFF;\n",
    "    }\n",
    "    #capture-button {\n",
    "        background-color: #3F52D9; \n",
    "        color: white;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        cursor: pointer;\n",
    "        font-size: 16px;\n",
    "        border-radius: 3px;\n",
    "        margin-top: 10px;\n",
    "        width: 190px;\n",
    "        margin-right: 20px;\n",
    "    }\n",
    "    #clear-button {\n",
    "        background-color: #FF0000,; \n",
    "        color: black;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        cursor: pointer;\n",
    "        font-size: 16px;\n",
    "        border-radius: 3px;\n",
    "        margin-top: 10px;\n",
    "        width: 190px;\n",
    "    }\n",
    "    #container {\n",
    "      display: flex;\n",
    "      flex-direction: column; /* Arrange children vertically */\n",
    "      align-items: center; /* Center horizontally */\n",
    "      justify-content: center;\n",
    "    }\n",
    "    #btn-container {\n",
    "      display: flex;\n",
    "      flex-direction: row; /* Arrange children vertically */\n",
    "      align-items: center; /* Center horizontally */\n",
    "    }\n",
    "\n",
    "</style>\n",
    "<div id='container'>\n",
    "<canvas id=\"whiteboard\" width=\"400\" height=\"200\" fill_rect='white'></canvas>\n",
    "<div id='btn-container'>\n",
    "<button id=\"capture-button\">Predict</button>\n",
    "<button id=\"clear-button\">Clear</button>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<script>\n",
    "    var canvas = document.getElementById('whiteboard');\n",
    "    var context = canvas.getContext('2d');\n",
    "    var drawing = false;\n",
    "    canvas.addEventListener('mousedown', function (e) {\n",
    "        drawing = true;\n",
    "        context.beginPath();\n",
    "        context.moveTo(e.clientX - canvas.getBoundingClientRect().left, e.clientY - canvas.getBoundingClientRect().top);\n",
    "    });\n",
    "    canvas.addEventListener('mousemove', function (e) {\n",
    "        if (drawing) {\n",
    "            context.lineTo(e.clientX - canvas.getBoundingClientRect().left, e.clientY - canvas.getBoundingClientRect().top);\n",
    "            context.stroke();\n",
    "        }\n",
    "    });\n",
    "    canvas.addEventListener('mouseup', function () {\n",
    "        drawing = false;\n",
    "    });\n",
    "    canvas.addEventListener('mouseout', function () {\n",
    "        drawing = false;\n",
    "    });\n",
    "    \n",
    "    var clearButton = document.getElementById('clear-button');\n",
    "    clearButton.addEventListener('click', function () {\n",
    "       context.clearRect(0, 0, canvas.width, canvas.height);\n",
    "    });\n",
    "\n",
    "   var captureButton = document.getElementById('capture-button');\n",
    "    captureButton.addEventListener('click', function () {\n",
    "       // Convert the canvas content to a data URL (image)\n",
    "    var imageData = canvas.toDataURL(\"image/png\");\n",
    "\n",
    "    // Send the image data to the Jupyter kernel variable\n",
    "    IPython.notebook.kernel.execute('image_data = \"' + imageData + '\"');\n",
    "    });\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import re\n",
    "import base64\n",
    "import torch\n",
    "\n",
    "# Extract the base64 portion of the data URL\n",
    "image_data_base64 = re.sub('^data:image/.+;base64,', '', image_data)\n",
    "\n",
    "# Decode the base64 string to bytes and create a PIL Image\n",
    "image_bytes = base64.b64decode(image_data_base64)\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "# Convert the PIL Image to a NumPy array\n",
    "image_np = np.array(image)\n",
    "image_tensor = torch.from_numpy(image_np)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
